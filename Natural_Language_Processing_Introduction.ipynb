{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM51RrwtyfX5PuAdAb0rKjX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwanandKale/AIML_Bootcamp/blob/main/Natural_Language_Processing_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJXBS9nfeXfR",
        "outputId": "276e9a9d-370c-43cb-9428-e1cf533f4c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------NLP Starting ---------\n"
          ]
        }
      ],
      "source": [
        "print(\"-------------NLP Starting ---------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1=\"Natural Language Processing is a subfield of AI\"\n",
        "tag1=\"NLP\"\n",
        "text2=\"Computer Vision is a subfield of AI\"\n",
        "tag2=\"CV\"\n"
      ],
      "metadata": {
        "id": "0RLaG3eNf8a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n"
      ],
      "metadata": {
        "id": "4X_twp4cgMZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Natural Language Processing is a subfield subfield of AI\",\n",
        "    \"Computer Vision is a subfield of AI\"\n",
        "]\n",
        "\n",
        "tags = [\"NLP\", \"CV\"]\n"
      ],
      "metadata": {
        "id": "63FmXfmAgnQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and vocabulary creation\n",
        "corpus = texts + tags\n",
        "\n",
        "# Learn the vocabulary from the corpus\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the vocabulary\n",
        "print(\"Vocabulary:\", feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc-cqCLugrR5",
        "outputId": "b3a6029c-223a-4db5-8841-5693f437e91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['ai' 'computer' 'cv' 'is' 'language' 'natural' 'nlp' 'of' 'processing'\n",
            " 'subfield' 'vision']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Count calculation and vectorization\n",
        "X = vectorizer.transform(texts)\n",
        "\n",
        "# Convert the sparse matrix to an array\n",
        "X_array = X.toarray()\n",
        "\n",
        "# Create a new matrix with labels and counts\n",
        "labels = np.array(tags)\n",
        "matrix_with_labels = np.concatenate((np.array([texts, labels]).T, X_array), axis=1)\n",
        "\n",
        "# Print the document-term matrix with labels and counts\n",
        "print(\"Document-Term Matrix:\")\n",
        "print(matrix_with_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KXYdDVCg1uQ",
        "outputId": "505fa1e3-d692-4c5f-ad6e-6b5fb678cc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document-Term Matrix:\n",
            "[['Natural Language Processing is a subfield subfield of AI' 'NLP' '1'\n",
            "  '0' '0' '1' '1' '1' '0' '1' '1' '2' '0']\n",
            " ['Computer Vision is a subfield of AI' 'CV' '1' '1' '0' '1' '0' '0' '0'\n",
            "  '1' '0' '1' '1']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Wayy\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the two texts and their corresponding tags\n",
        "\n",
        "text1 = \"Natural Language Processing is a subfield of AI\"\n",
        "\n",
        "tag1 = \"NLP\"\n",
        "\n",
        "text2 = \"Computer Vision is a subfield of AI\"\n",
        "\n",
        "tag2 = \"CV\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Fit the vectorizer on the texts and transform them into feature vectors\n",
        "\n",
        "X = vectorizer.fit_transform([text1, text2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the feature names (words)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the frequency table as a matrix\n",
        "\n",
        "frequency_table = X.toarray()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame to hold the frequency table\n",
        "\n",
        "df = pd.DataFrame(frequency_table, columns=feature_names)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Add the text and tag columns\n",
        "\n",
        "df['Text'] = [text1, text2]\n",
        "\n",
        "df['Tag'] = [tag1, tag2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the DataFrame\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ALbNCKg3Cz",
        "outputId": "96841b38-605c-4879-d0a2-c7672dabc45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ai  computer  is  language  natural  of  processing  subfield  vision  \\\n",
            "0   1         0   1         1        1   1           1         1       0   \n",
            "1   1         1   1         0        0   1           0         1       1   \n",
            "\n",
            "                                              Text  Tag  \n",
            "0  Natural Language Processing is a subfield of AI  NLP  \n",
            "1              Computer Vision is a subfield of AI   CV  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enchancing vectorizer with Lemmatizer"
      ],
      "metadata": {
        "id": "PV7CDFXL_7tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(['punkt','wordnet'])\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiVW9i5o_r_n",
        "outputId": "72e2bbd2-6b6f-40fd-f76f-52ae1aadd6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#punkt -> we required tokenizer\n",
        "#wordnet -> lemmatizer\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lenm=WordNetLemmatizer()\n",
        "\n",
        "print(lenm.lemmatize(\"mouse\"))\n",
        "print(lenm.lemmatize(\"feet\"))\n",
        "print(lenm.lemmatize(\"caring\"))\n",
        "print(lenm.lemmatize(\"houses\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Ti_QU3Aji-",
        "outputId": "6911c588-0e17-4874-9d40-f4ee5cd6c5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mouse\n",
            "foot\n",
            "caring\n",
            "house\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"My Gradma is very caring. The striped bats are hanging on their feet\"\n",
        "\n",
        "#first step : tokenization\n",
        "li_words=nltk.word_tokenize(sentence)\n",
        "\n",
        "print(li_words)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27yzMjW6BUPP",
        "outputId": "b8efa51b-3ad6-47ef-9215-dd383153746e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'Gradma', 'is', 'very', 'caring', '.', 'The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output=[lenm.lemmatize(w) for w in li_words]\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYQdft5ByZp",
        "outputId": "e6a2420f-25b8-47c0-8e0c-c6cc97fc312b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'Gradma', 'is', 'very', 'caring', '.', 'The', 'striped', 'bat', 'are', 'hanging', 'on', 'their', 'foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to provide (part of speech ) tag as second argument to lemmatize"
      ],
      "metadata": {
        "id": "FHoG-TM6DAI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lenm.lemmatize(\"caring\",\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi1ZV7U3DKcg",
        "outputId": "135bcaa5-b199-473c-d369-1d466b7a3c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lenm.lemmatize(\"stripes\",\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Wf_eZSDSLw",
        "outputId": "49ec9b3c-bd0c-43dd-c313-7816976747ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "strip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lenm.lemmatize(\"stripes\",\"n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JQwPR91DasW",
        "outputId": "45b7fc25-0fd9-4d3d-dfcd-e9bba1b28043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stripe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lenm.lemmatize(\"hanging\",\"v\"))\n",
        "print(lenm.lemmatize(\"are\",\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyqyFjJFDfjc",
        "outputId": "0991dcd6-5b09-4cbb-b892-fe1feb5545a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hang\n",
            "be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuNytae3EevI",
        "outputId": "01a0dfb5-be66-4094-d3c1-ec4db6497442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordNet lemmatizer with POS tag"
      ],
      "metadata": {
        "id": "cF-mpHRmDycA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos_tag(word):\n",
        "  tag=nltk.pos_tag([word])\n",
        "  return tag\n",
        "\n",
        "get_wordnet_pos_tag(\"caring\")\n",
        "get_wordnet_pos_tag(\"he\")\n",
        "get_wordnet_pos_tag(\"other\")\n",
        "\n",
        "get_wordnet_pos_tag(\"Slowly\")\n",
        "get_wordnet_pos_tag(\"Happily\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHd6CA8FD2Ll",
        "outputId": "63327302-327e-41ef-d52f-bffd97919726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Happily', 'RB')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader import wordnet\n",
        "def get_wordnet_pos_tag(word):\n",
        "  tag=nltk.pos_tag([word])[0][1][0]\n",
        "\n",
        "  tag_dict={\n",
        "      \"J\":wordnet.ADJ,\n",
        "      \"R\":wordnet.ADV,\n",
        "      \"N\":wordnet.NOUN,\n",
        "      \"V\":wordnet.VERB\n",
        "  }\n",
        "  print(tag)\n",
        "  return tag_dict.get(tag,wordnet.NOUN) #wordnet.NOUN it is default value\n",
        "\n",
        "get_wordnet_pos_tag(\"caring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VwsmfjkxFdfy",
        "outputId": "dcd1dd69-fb00-4484-c4db-096c0d5fd2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenm=WordNetLemmatizer()\n",
        "\n",
        "word=\"caring\"\n",
        "\n",
        "print(lenm.lemmatize(word,get_wordnet_pos_tag(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q1NOqGKHDrx",
        "outputId": "63f2013e-4bda-471f-979d-c3dc4d1b043a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V\n",
            "care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=\"brave\"\n",
        "\n",
        "print(lenm.lemmatize(word,get_wordnet_pos_tag(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V-JB7oFHVS8",
        "outputId": "be2f39ac-2656-4b24-b292-3ed737fcaa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N\n",
            "brave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"My Gradma is very caring. The striped bats are hanging on their feet\"\n",
        "\n",
        "#first step : tokenization\n",
        "li_words=nltk.word_tokenize(sentence)\n",
        "\n",
        "output=[lenm.lemmatize(w,get_wordnet_pos_tag(w)) for w in li_words]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6suJvpUfIFSw",
        "outputId": "2e26fe53-732c-4b31-87f5-8ee5183f3131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P\n",
            "N\n",
            "V\n",
            "R\n",
            "V\n",
            ".\n",
            "D\n",
            "V\n",
            "N\n",
            "V\n",
            "V\n",
            "I\n",
            "P\n",
            "N\n",
            "['My', 'Gradma', 'be', 'very', 'care', '.', 'The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy Lemmatizer**\n"
      ],
      "metadata": {
        "id": "-ywVJGHnIfED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "sp_nlp=spacy.load('en_core_web_sm') #updated model name\n",
        "\n",
        "sentence=\"My Gradma is very caring. The striped bats are hanging on their feet\"\n",
        "\n",
        "doc=sp_nlp(sentence)\n",
        "print(doc)\n",
        "\n",
        "#extract lemma for each token in sentence\n",
        "lemmas=[token.lemma_ for token in doc]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7DuqFV5InJJ",
        "outputId": "554cce89-cbdf-4f91-eb51-1df20070fa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Gradma is very caring. The striped bats are hanging on their feet\n",
            "['my', 'Gradma', 'be', 'very', 'caring', '.', 'the', 'stripe', 'bat', 'be', 'hang', 'on', 'their', 'foot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By spacy another method\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sentence = \"My Grandma is very caring. The striped bats are hanging on their feet.\"\n",
        "\n",
        "# Process the sentence with spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Extract lemmas for each token\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "\n",
        "print(lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiF0llMJIyky",
        "outputId": "55f24ef6-c45c-474c-94b1-eccfa95121f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'Grandma', 'be', 'very', 'caring', '.', 'the', 'stripe', 'bat', 'be', 'hang', 'on', 'their', 'foot', '.']\n"
          ]
        }
      ]
    }
  ]
}